import React, { useCallback, useEffect, useMemo, useRef, useState } from 'react'
import { Mic, MicOff, X, Send, Loader2, Activity, BookOpen, Brain, Upload, Maximize2, Minimize2, User } from 'lucide-react'
import clsx from 'clsx'
import NoaAnimatedAvatar from './NoaAnimatedAvatar'
import { useNoaPlatform } from '../contexts/NoaPlatformContext'
import { useMedCannLabConversation } from '../hooks/useMedCannLabConversation'
import { useAuth } from '../contexts/AuthContext'
import { supabase } from '../lib/supabase'
import { KnowledgeBaseIntegration } from '../services/knowledgeBaseIntegration'
import { normalizeUserType } from '../lib/userTypes'
import * as pdfjsLib from 'pdfjs-dist'

// Configurar PDF.js worker
try {
  pdfjsLib.GlobalWorkerOptions.workerSrc = `https://cdnjs.cloudflare.com/ajax/libs/pdf.js/${pdfjsLib.version}/pdf.worker.min.js`
} catch (err) {
  console.warn('Erro ao configurar PDF.js worker:', err)
}

interface NoaConversationalInterfaceProps {
  userCode?: string
  userName?: string
  position?: 'bottom-right' | 'bottom-left' | 'top-right' | 'top-left' | 'inline'
  hideButton?: boolean
}

const getPositionClasses = (position: NoaConversationalInterfaceProps['position']) => {
  switch (position) {
    case 'bottom-left':
      return 'bottom-4 left-4'
    case 'top-right':
      return 'top-4 right-4'
    case 'top-left':
      return 'top-4 left-4'
    case 'bottom-right':
      return 'bottom-4 right-4'
    case 'inline':
      return ''
    default:
      return 'bottom-4 right-4'
  }
}

type RecognitionHandle = {
  recognition: any
  timer?: number
  buffer: string
  stopped?: boolean
  retryCount?: number
  maxRetries?: number
  lastError?: string | null
  startTime?: number // Timestamp de quando iniciou a escuta
  maxDuration?: number // Dura√ß√£o m√°xima em ms (padr√£o: 30 segundos)
  inactivityTimer?: number // Timer para detectar inatividade
  restartScheduled?: boolean // Flag para evitar m√∫ltiplas tentativas de rein√≠cio simult√¢neas
}

const NoaConversationalInterface: React.FC<NoaConversationalInterfaceProps> = ({
  userCode = 'DR-001',
  userName = 'Dr. Ricardo Valen√ßa',
  position = 'bottom-right',
  hideButton = false
}) => {
  const { isOpen: contextIsOpen, pendingMessage, clearPendingMessage, closeChat } = useNoaPlatform()
  const [isOpen, setIsOpen] = useState(hideButton || contextIsOpen)
  const [isExpanded, setIsExpanded] = useState(false)
  const [inputValue, setInputValue] = useState('')
  const [isListening, setIsListening] = useState(false)
  const [shouldAutoResume, setShouldAutoResume] = useState(false)
  const [isUploading, setIsUploading] = useState(false)
  const [uploadProgress, setUploadProgress] = useState(0)
  const [showUploadModal, setShowUploadModal] = useState(false)
  const [uploadedFile, setUploadedFile] = useState<File | null>(null)
  const [uploadCategory, setUploadCategory] = useState('ai-documents')
  const [uploadArea, setUploadArea] = useState('cannabis')
  const [uploadUserType, setUploadUserType] = useState<string[]>(['professional', 'student'])
  // Estados para grava√ß√£o de consulta
  const [isRecordingConsultation, setIsRecordingConsultation] = useState(false)
  const [selectedPatientId, setSelectedPatientId] = useState<string | null>(null)
  const [consultationTranscript, setConsultationTranscript] = useState<string[]>([])
  const [consultationStartTime, setConsultationStartTime] = useState<Date | null>(null)
  const [showPatientSelector, setShowPatientSelector] = useState(false)
  const [availablePatients, setAvailablePatients] = useState<any[]>([])
  const [isSavingConsultation, setIsSavingConsultation] = useState(false)
  const recognitionRef = useRef<RecognitionHandle | null>(null)
  const consultationRecognitionRef = useRef<any>(null) // Para grava√ß√£o de consulta
  const scrollContainerRef = useRef<HTMLDivElement | null>(null)
  const fileInputRef = useRef<HTMLInputElement | null>(null)
  const isListeningRef = useRef(false) // Ref para verificar estado atual de isListening
  const immediateListenTimeoutRef = useRef<number | null>(null)
  const autoResumeRequestedRef = useRef(false)
  const wasSpeakingRef = useRef(false) // Ref para rastrear quando a IA estava falando
  const lastSpeechEndTimeRef = useRef<number>(0) // Timestamp da √∫ltima vez que a IA terminou de falar
  const hasActiveSimulationRef = useRef(false) // Ref para rastrear se h√° simula√ß√£o ativa
  const isStartingRef = useRef(false) // Lock para evitar m√∫ltiplas inicializa√ß√µes simult√¢neas
  const hasUserEnabledMicRef = useRef(false) // Flag para rastrear quando o usu√°rio explicitamente ativou o microfone
  const { user } = useAuth()

  const {
    messages,
    sendMessage,
    isProcessing,
    isSpeaking,
    error,
    usedEndpoints,
    lastIntent
  } = useMedCannLabConversation()

  // Inicializar wasSpeakingRef com o estado inicial de isSpeaking
  useEffect(() => {
    // Atualizar timestamp quando a IA termina de falar
    if (wasSpeakingRef.current && !isSpeaking) {
      lastSpeechEndTimeRef.current = Date.now()
      console.log('üîá IA terminou de falar, registrando timestamp para evitar eco')
    }
    wasSpeakingRef.current = isSpeaking
    console.log('üé§ wasSpeakingRef inicializado:', isSpeaking)
  }, [isSpeaking]) // Atualizar sempre que isSpeaking mudar

  useEffect(() => {
    const container = scrollContainerRef.current
    if (container) {
      container.scrollTo({ top: container.scrollHeight, behavior: 'smooth' })
    }

    // Atualizar ref de simula√ß√£o ativa sempre que as mensagens mudarem
    const hasActiveSimulation = messages.some(msg => {
      const metadata = msg.metadata as Record<string, any> | undefined
      return metadata?.simulationActive === true &&
        metadata?.simulationRole === 'patient'
    })

    // Verificar se h√° avalia√ß√£o cl√≠nica ativa
    // O metadata pode estar aninhado (metadata.metadata) ou direto
    const hasActiveAssessment = messages.some(msg => {
      const metadata = msg.metadata as Record<string, any> | undefined
      const nestedMetadata = metadata?.metadata as Record<string, any> | undefined

      return metadata?.assessmentActive === true ||
        nestedMetadata?.assessmentActive === true ||
        metadata?.type === 'assessment' ||
        nestedMetadata?.type === 'assessment' ||
        (metadata?.intent === 'IMRE_ANALYSIS' && nestedMetadata?.assessmentActive !== false)
    })

    hasActiveSimulationRef.current = hasActiveSimulation || hasActiveAssessment

    if (hasActiveSimulation) {
      console.log('üé≠ Simula√ß√£o ativa detectada - microfone ter√° prioridade m√°xima')
    }
    if (hasActiveAssessment) {
      console.log('üìã Avalia√ß√£o cl√≠nica ativa detectada - microfone ter√° prioridade m√°xima')
    }

    // Log detalhado para debug
    if (hasActiveAssessment || hasActiveSimulation) {
      const lastMessage = messages[messages.length - 1]
      if (lastMessage) {
        console.log('üîç Metadata da √∫ltima mensagem:', {
          metadata: lastMessage.metadata,
          nestedMetadata: (lastMessage.metadata as Record<string, any>)?.metadata
        })
      }
    }
  }, [messages])

  useEffect(() => {
    // Se hideButton √© true, sempre abrir (sem bot√£o)
    // Se contextIsOpen √© true, abrir o chat
    const shouldBeOpen = hideButton || contextIsOpen
    console.log('üîç NoaConversationalInterface - Atualizando isOpen:', { shouldBeOpen, hideButton, contextIsOpen })
    setIsOpen(shouldBeOpen)
  }, [contextIsOpen, hideButton])

  useEffect(() => {
    if (pendingMessage) {
      console.log('üì® Processando mensagem pendente:', pendingMessage.substring(0, 100))
      setInputValue(pendingMessage)
      // Aguardar um pouco para garantir que o chat esteja totalmente pronto
      setTimeout(() => {
        sendMessage(pendingMessage)
        clearPendingMessage()
        // Limpar o input ap√≥s enviar a mensagem pendente
        setInputValue('')
      }, 500)
    }
  }, [pendingMessage, sendMessage, clearPendingMessage])

  useEffect(() => {
    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.stopped = true
        if (recognitionRef.current.timer) {
          window.clearTimeout(recognitionRef.current.timer)
          recognitionRef.current.timer = undefined
        }
        recognitionRef.current.recognition.onresult = null
        recognitionRef.current.recognition.onerror = null
        recognitionRef.current.recognition.onend = null
        recognitionRef.current.recognition.stop()
        const text = recognitionRef.current.buffer.trim()
        if (text.length > 0) {
          sendMessage(text, { preferVoice: true })
        }
        recognitionRef.current = null
      }
    }
  }, [sendMessage])

  const stopListening = useCallback(() => {
    // REMOVIDO: Todas as prote√ß√µes que impediam parar o microfone
    // Controle 100% manual - usu√°rio pode parar quando quiser

    console.log('üõë Parando escuta de voz (chat fechado)...')

    // Verificar estado atual antes de parar
    if (recognitionRef.current && recognitionRef.current.recognition) {
      try {
        const currentState = recognitionRef.current.recognition.state
        console.log('üîç Estado do reconhecimento antes de parar:', currentState)
      } catch (e) {
        console.warn('‚ö†Ô∏è N√£o foi poss√≠vel verificar estado antes de parar:', e)
      }
    }

    // Atualizar ref PRIMEIRO para evitar rein√≠cio
    isListeningRef.current = false

    const handle = recognitionRef.current
    if (handle) {
      handle.stopped = true

      // Limpar todos os timers
      if (handle.timer) {
        window.clearTimeout(handle.timer)
        handle.timer = undefined
      }
      if (handle.inactivityTimer) {
        window.clearTimeout(handle.inactivityTimer)
        handle.inactivityTimer = undefined
      }
      // Limpar timer de dura√ß√£o m√°xima
      const maxTimer = (handle as any).maxDurationTimer
      if (maxTimer) {
        window.clearTimeout(maxTimer)
          ; (handle as any).maxDurationTimer = undefined
      }

      // Limpar timer de fallback se existir
      const fallbackTimer = (handle as any).fallbackTimer
      if (fallbackTimer) {
        window.clearTimeout(fallbackTimer)
          ; (handle as any).fallbackTimer = undefined
      }

      // Remover callbacks para evitar rein√≠cio
      handle.recognition.onresult = null
      handle.recognition.onerror = null
      handle.recognition.onend = null
      try {
        handle.recognition.stop()
      } catch (e) {
        // Ignorar erros ao parar
      }

      // Enviar texto capturado se houver
      const text = handle.buffer.trim()
      if (text.length > 0) {
        sendMessage(text, { preferVoice: true })
      }

      recognitionRef.current = null
    }
    setIsListening(false)
  }, [sendMessage, isOpen])

  const startListening = useCallback(async (force: boolean = false): Promise<void> => {
    console.log('üé§ startListening chamado. Estado atual:', {
      isOpen,
      isProcessing,
      isSpeaking,
      isListening: isListeningRef.current,
      hasActiveSimulation: hasActiveSimulationRef.current,
      isStarting: isStartingRef.current,
      force
    })

    // Se for for√ßado (a√ß√£o manual do usu√°rio), ignorar verifica√ß√µes de estado
    if (!force) {
      // Verificar se j√° est√° iniciando - ignorar chamadas duplicadas
      if (isStartingRef.current) {
        console.log('‚è≥ J√° h√° uma inicializa√ß√£o em andamento, ignorando chamada duplicada')
        return
      }

      // Verificar se j√° est√° realmente ouvindo
      if (recognitionRef.current && recognitionRef.current.recognition) {
        try {
          const currentState = recognitionRef.current.recognition.state
          if (currentState === 'listening' || currentState === 'starting') {
            console.log('‚úÖ Reconhecimento j√° est√° ativo, n√£o reiniciar:', currentState)
            return
          }
        } catch (e) {
          // Continuar se n√£o conseguir verificar
        }
      }
    } else {
      // Se for for√ßado, limpar qualquer estado bloqueante
      isStartingRef.current = false
      console.log('üîÑ In√≠cio for√ßado - limpando estados bloqueantes')
    }

    if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
      console.warn('‚ö†Ô∏è Reconhecimento de voz n√£o suportado neste navegador.')
      alert('Reconhecimento de voz n√£o est√° dispon√≠vel no seu navegador. Por favor, use o campo de texto para digitar sua mensagem.')
      return
    }

    // Marcar como iniciando
    isStartingRef.current = true

    // Limpar qualquer reconhecimento anterior que possa estar travado
    if (recognitionRef.current && recognitionRef.current.recognition) {
      try {
        const currentState = recognitionRef.current.recognition.state
        console.log('üîç Estado do reconhecimento anterior:', currentState)
        if (currentState === 'listening' || currentState === 'starting') {
          console.log('üîÑ Parando reconhecimento anterior antes de iniciar novo')
          recognitionRef.current.recognition.stop()
          recognitionRef.current.stopped = true
        }
      } catch (e) {
        console.log('‚ÑπÔ∏è N√£o foi poss√≠vel verificar estado do reconhecimento, continuando...')
      }
    }

    // Resetar estados antes de iniciar
    isListeningRef.current = false
    setIsListening(false)

    // Verificar permiss√µes de microfone antes de iniciar
    try {
      if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
        // Liberar stream imediatamente - s√≥ precisamos verificar permiss√£o
        stream.getTracks().forEach(track => track.stop())
      }
    } catch (error: any) {
      console.error('‚ùå Erro ao verificar permiss√£o de microfone:', error)
      if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
        alert('Permiss√£o de microfone negada. Por favor, permita o acesso ao microfone nas configura√ß√µes do navegador e tente novamente.')
        return
      } else if (error.name === 'NotFoundError' || error.name === 'DevicesNotFoundError') {
        alert('Nenhum microfone encontrado. Verifique se o dispositivo est√° conectado e tente novamente.')
        return
      } else {
        console.warn('‚ö†Ô∏è Aviso ao verificar permiss√£o, mas continuando...', error)
      }
    }

    // Parar fala da IA imediatamente quando iniciar escuta
    if (typeof window !== 'undefined' && 'speechSynthesis' in window) {
      window.speechSynthesis.cancel()
    }
    window.dispatchEvent(new Event('noaStopSpeech'))

    // N√ÉO parar escuta anterior - deixar que o onend cuide do rein√≠cio
    // Isso evita abortar o microfone desnecessariamente

    console.log('üé§ Iniciando escuta de voz...')

    const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition
    const recognition: any = new SpeechRecognition()

    // Configura√ß√µes otimizadas para melhor reconhecimento
    recognition.lang = 'pt-BR'
    recognition.continuous = false // CHAT COMUM: n√£o cont√≠nuo - para quando o usu√°rio para de falar
    recognition.interimResults = true // Mostrar resultados intermedi√°rios no input
    recognition.maxAlternatives = 1 // Uma alternativa √© suficiente

    // Configura√ß√µes adicionais para melhorar qualidade (se dispon√≠veis)
    // REMOVIDO: grammars causava erro - n√£o √© necess√°rio para funcionamento b√°sico
    // if ('grammars' in recognition) {
    //   recognition.grammars = null // Isso causava erro TypeError
    // }

    // Configura√ß√µes de √°udio (se dispon√≠veis)
    // REMOVIDO: serviceURI n√£o √© padr√£o e pode causar problemas
    // if ('serviceURI' in recognition) {
    //   recognition.serviceURI = 'wss://speech.googleapis.com/v1/speech:recognize'
    // }

    const handle: RecognitionHandle = {
      recognition,
      buffer: '',
      retryCount: 0,
      maxRetries: 3,
      lastError: null,
      startTime: Date.now(),
      maxDuration: 15000, // 15 segundos m√°ximo
      inactivityTimer: undefined,
      restartScheduled: false // Inicializar flag de rein√≠cio agendado
    }
    recognitionRef.current = handle

    // Timer m√°ximo: parar ap√≥s 15 segundos (ser√° limpo em stopListening)
    let maxDurationTimer: number | undefined = undefined

    const flush = () => {
      const text = handle.buffer.trim()
      console.log('üîÑ flush() chamado. Buffer:', text, 'Tamanho:', text.length)
      if (text.length > 0) {
        console.log('üì§ Enviando mensagem capturada por voz:', text)
        try {
          // Limpar o input antes de enviar
          setInputValue('')
          sendMessage(text, { preferVoice: true })
          console.log('‚úÖ sendMessage chamado com sucesso')
          handle.buffer = ''
        } catch (error) {
          console.error('‚ùå Erro ao enviar mensagem:', error)
        }
      } else {
        console.log('‚ö†Ô∏è flush() chamado mas buffer est√° vazio')
      }
      // REMOVIDO: N√£o parar microfone ap√≥s enviar mensagem - manter sempre ligado
      // if (handle.stopped !== true) {
      //   handle.stopped = true
      //   stopListening()
      // }
    }

    const scheduleFlush = () => {
      // Limpar timer anterior
      if (handle.timer) {
        window.clearTimeout(handle.timer)
      }
      // Limpar timer de inatividade
      if (handle.inactivityTimer) {
        window.clearTimeout(handle.inactivityTimer)
        handle.inactivityTimer = undefined
      }

      // Timer para enviar ap√≥s 1.5 segundos de sil√™ncio (aumentado de 900ms)
      console.log('‚è∞ Agendando flush() em 1.5s. Buffer atual:', handle.buffer)
      handle.timer = window.setTimeout(() => {
        console.log('‚è∞ Timer de flush() disparado. Buffer:', handle.buffer)
        flush()
      }, 1500)

      // REMOVIDO: Timer de inatividade - o microfone deve ficar sempre ligado
      // handle.inactivityTimer = window.setTimeout(() => {
      //   if (handle.buffer.trim().length === 0) {
      //     console.log('‚è±Ô∏è Sem atividade de voz por 5 segundos, parando microfone')
      //     handle.stopped = true
      //     stopListening()
      //   }
      // }, 5000)
    }

      // REMOVIDO: Timeout m√°ximo - o microfone deve ficar sempre ligado
      // maxDurationTimer = window.setTimeout(() => {
      //   if (recognitionRef.current === handle && !handle.stopped) {
      //     console.log('‚è±Ô∏è Tempo m√°ximo de escuta atingido (15s), parando microfone')
      //     const text = handle.buffer.trim()
      //     if (text.length > 0) {
      //       flush()
      //     } else {
      //       handle.stopped = true
      //       stopListening()
      //     }
      //   }
      // }, handle.maxDuration || 15000)

      // Armazenar timer no handle para poder limpar depois
      ; (handle as any).maxDurationTimer = maxDurationTimer

    // Fun√ß√£o para limpar caracteres especiais inv√°lidos
    const cleanTranscript = (text: string): string => {
      // Remover caracteres especiais inv√°lidos comuns em erros de reconhecimento
      return text
        .replace(/[~*]/g, '') // Remover ~ e *
        .replace(/\s+/g, ' ') // Normalizar espa√ßos m√∫ltiplos
        .trim()
    }

    // Fun√ß√£o para validar se o texto n√£o parece ser eco da IA
    // SIMPLIFICADA: Aceitar quase tudo, apenas rejeitar texto vazio
    const isValidUserInput = (text: string): boolean => {
      const cleaned = cleanTranscript(text.toLowerCase())

      // Apenas rejeitar texto completamente vazio
      if (cleaned.length < 1) {
        console.log('‚ö†Ô∏è Texto vazio, rejeitando')
        return false
      }

      // Aceitar qualquer texto n√£o vazio - confiar no usu√°rio
      return true
    }

    recognition.onresult = (event: any) => {
      console.log('üé§ onresult disparado! N√∫mero de resultados:', event.results.length, 'resultIndex:', event.resultIndex)

      // REMOVIDO: Todas as verifica√ß√µes de bloqueio - deixar o microfone funcionar livremente
      // O usu√°rio pode falar a qualquer momento

      // Resetar timer de inatividade quando h√° atividade
      if (handle.inactivityTimer) {
        window.clearTimeout(handle.inactivityTimer)
        handle.inactivityTimer = undefined
      }

      let allFinalTexts: string[] = []
      let allIntermediateTexts: string[] = []

      // Processar todos os resultados do evento atual
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const result = event.results[i]
        const rawTranscript = result[0].transcript.trim()
        const cleanedTranscript = cleanTranscript(rawTranscript)

        if (cleanedTranscript.length > 0) {
          if (result.isFinal) {
            // Resultado FINAL: SEMPRE aceitar e processar
            allFinalTexts.push(cleanedTranscript)
            console.log('üé§ Texto capturado (final, limpo):', cleanedTranscript, '(original:', rawTranscript + ')')
            // Atualizar input imediatamente
            setInputValue(cleanedTranscript)
          } else {
            // Resultado intermedi√°rio: mostrar no input imediatamente para feedback visual
            allIntermediateTexts.push(cleanedTranscript)
            console.log('üé§ Texto capturado (intermedi√°rio, limpo):', cleanedTranscript, '(original:', rawTranscript + ')')
            // Atualizar input imediatamente com texto intermedi√°rio
            const currentIntermediate = allIntermediateTexts.join(' ')
            setInputValue(currentIntermediate)
            handle.buffer = currentIntermediate.trim()
            console.log('üìù Input atualizado com texto intermedi√°rio:', currentIntermediate)
          }
        }
      }

      // Se houver resultados FINAIS, usar apenas o √∫ltimo (mais completo)
      if (allFinalTexts.length > 0) {
        // Usar o √∫ltimo resultado final (geralmente o mais completo)
        const finalText = allFinalTexts[allFinalTexts.length - 1]

        // IMPORTANTE: Substituir o buffer ao inv√©s de acumular
        // Isso evita duplica√ß√µes de m√∫ltiplos eventos onresult
        handle.buffer = finalText.trim()

        // Atualizar o input para feedback visual
        setInputValue(finalText.trim())

        console.log('‚úÖ MICROFONE FUNCIONANDO! Texto final capturado e validado:', finalText)
        console.log('üìù Buffer atualizado (substitu√≠do):', handle.buffer)
        console.log('üìù Input atualizado com texto capturado')

        // Agendar envio ap√≥s sil√™ncio
        scheduleFlush()
      } else if (allIntermediateTexts.length > 0) {
        // Se n√£o h√° resultado final mas h√° texto intermedi√°rio, mostrar no input para feedback visual
        const intermediateText = allIntermediateTexts.join(' ')
        console.log('‚úÖ MICROFONE FUNCIONANDO! Texto intermedi√°rio:', intermediateText)
        // Atualizar input com texto intermedi√°rio para feedback visual
        // IMPORTANTE: Substituir qualquer texto pr√©-existente
        setInputValue(intermediateText)
        // Tamb√©m atualizar o buffer com texto intermedi√°rio para garantir que seja enviado se n√£o houver resultado final
        handle.buffer = intermediateText.trim()
        console.log('üìù Input e buffer atualizados com texto intermedi√°rio:', intermediateText)
        // N√ÉO agendar flush ainda - aguardar resultado final, mas manter no buffer
      } else {
        console.log('‚ö†Ô∏è onresult chamado mas sem texto capturado v√°lido')
      }
    }

    recognition.onerror = (event: any) => {
      handle.lastError = event.error

      // Logar todos os erros para debug com mais detalhes
      console.error('üîç Erro no reconhecimento de voz:', {
        error: event.error,
        message: event.message || 'Sem mensagem',
        state: recognition.state,
        timestamp: new Date().toISOString(),
        handleMatch: recognitionRef.current === handle,
        isOpen,
        hasActiveSimulation: hasActiveSimulationRef.current
      })

      // Ignorar erros n√£o cr√≠ticos silenciosamente
      if (event.error === 'no-speech') {
        console.log('‚ÑπÔ∏è Nenhuma fala detectada (normal)')
        return
      }

      if (event.error === 'aborted') {
        console.log('‚ÑπÔ∏è Reconhecimento abortado (normal)')
        // Marcar que houve abort para prevenir rein√≠cio autom√°tico
        handle.lastError = 'aborted'
        handle.stopped = true
        setIsListening(false)
        isListeningRef.current = false
        // N√ÉO reiniciar automaticamente ap√≥s abort - isso causa loop infinito
        console.log('‚ÑπÔ∏è Reconhecimento abortado - n√£o reiniciando automaticamente')
        return
      }

      // Para erros cr√≠ticos, logar e informar usu√°rio
      console.error('‚ùå Erro cr√≠tico no reconhecimento de voz:', event.error)

      if (handle.timer) {
        window.clearTimeout(handle.timer)
        handle.timer = undefined
      }

      // Limpar timer de inatividade
      if (handle.inactivityTimer) {
        window.clearTimeout(handle.inactivityTimer)
        handle.inactivityTimer = undefined
      }

      // Limpar timer de dura√ß√£o m√°xima
      if ((handle as any).maxDurationTimer) {
        window.clearTimeout((handle as any).maxDurationTimer)
          ; (handle as any).maxDurationTimer = undefined
      }

      // Tentar enviar o que foi capturado antes do erro
      const text = handle.buffer.trim()
      if (text.length > 0) {
        flush()
      }

      // Parar sempre em caso de erro - n√£o tentar reiniciar automaticamente
      handle.stopped = true
      setIsListening(false)
      isListeningRef.current = false
      recognitionRef.current = null

      // Informar usu√°rio apenas para erros cr√≠ticos
      if (event.error === 'not-allowed' || event.error === 'service-not-allowed') {
        console.warn('‚ö†Ô∏è Permiss√£o de microfone negada')
        alert('Permiss√£o de microfone negada. Por favor, permita o acesso ao microfone nas configura√ß√µes do navegador e tente novamente.')
      } else if (event.error === 'audio-capture') {
        alert('N√£o foi poss√≠vel acessar o microfone. Verifique se o dispositivo est√° conectado e tente novamente.')
      } else if (event.error === 'network') {
        console.warn('‚ö†Ô∏è Erro de rede no reconhecimento de voz')
        // N√£o mostrar alerta para erro de rede - pode ser tempor√°rio
      }
    }

    // Handler para quando o reconhecimento realmente come√ßar
    recognition.onstart = () => {
      console.log('üé§ Reconhecimento de voz iniciado (onstart)')
      // Limpar timer de fallback se existir
      if ((handle as any).fallbackTimer) {
        clearTimeout((handle as any).fallbackTimer)
          ; (handle as any).fallbackTimer = undefined
      }
      // Sincronizar estado quando realmente come√ßar
      if (recognitionRef.current === handle) {
        setIsListening(true)
        isListeningRef.current = true
        isStartingRef.current = false // Liberar lock
        // Marcar que o usu√°rio ativou o microfone com sucesso
        hasUserEnabledMicRef.current = true
        console.log('‚úÖ Estado atualizado via onstart - usu√°rio ativou microfone')
      }
    }

    recognition.onend = () => {
      console.log('üõë Evento onend disparado - microfone parou')

      // Enviar texto capturado se houver
      if (handle.buffer.trim().length > 0) {
        console.log('üì§ Enviando texto capturado:', handle.buffer)
        if (handle.timer) {
          window.clearTimeout(handle.timer)
          handle.timer = undefined
        }
        flush()
      }

      // SEMPRE parar o microfone quando onend disparar
      // Controle 100% manual - usu√°rio clica para ligar novamente
      console.log('‚úÖ Microfone parou - controle manual: clique no bot√£o para ligar novamente')
      setIsListening(false)
      isListeningRef.current = false
      recognitionRef.current = null
    }

    try {
      // N√ÉO parar reconhecimento anterior - deixar que o onend cuide do rein√≠cio
      // Isso evita abortar o microfone desnecessariamente

      recognition.start()
      // N√ÉO atualizar estado imediatamente - esperar confirma√ß√£o de que realmente iniciou
      // O estado s√≥ ser√° atualizado quando onstart disparar (linha 494-506)
      autoResumeRequestedRef.current = false
      console.log('üé§ Comando start() enviado ao reconhecimento - aguardando confirma√ß√£o...')
      console.log('üîç Configura√ß√£o:', {
        lang: recognition.lang,
        continuous: recognition.continuous,
        interimResults: recognition.interimResults
      })

      // Fallback: se onstart n√£o disparar em 1 segundo, verificar estado real
      const fallbackTimer = setTimeout(() => {
        if (recognitionRef.current === handle && !isListeningRef.current) {
          console.log('‚ö†Ô∏è onstart n√£o disparou ap√≥s 1s, verificando estado real do reconhecimento...')
          try {
            const state = recognition.state
            console.log('üîç Estado real do reconhecimento:', state)
            if (state === 'listening' || state === 'starting') {
              // S√≥ atualizar se realmente estiver funcionando
              setIsListening(true)
              isListeningRef.current = true
              isStartingRef.current = false // Liberar lock
              console.log('‚úÖ Estado atualizado via fallback - reconhecimento confirmado como ativo')
            } else if (state === 'idle' || state === 'aborted') {
              // Reconhecimento n√£o iniciou - tentar novamente se for avalia√ß√£o ativa
              const hasActiveSimulation = hasActiveSimulationRef.current
              isStartingRef.current = false // Liberar lock mesmo se falhar

              if (hasActiveSimulation) {
                console.log('üîÑ Avalia√ß√£o/Simula√ß√£o ativa - tentando reiniciar reconhecimento...')
                setTimeout(() => {
                  if (recognitionRef.current === handle && isOpen && !isStartingRef.current) {
                    try {
                      recognition.start()
                      console.log('üîÑ Tentativa de rein√≠cio do reconhecimento')
                    } catch (e) {
                      console.error('‚ùå Erro ao tentar reiniciar:', e)
                    }
                  }
                }, 500)
              } else {
                console.error('‚ùå Reconhecimento N√ÉO iniciou! Estado:', state)
                setIsListening(false)
                isListeningRef.current = false
                recognitionRef.current = null
                // N√£o mostrar alerta - apenas logar
                console.warn('‚ö†Ô∏è N√£o foi poss√≠vel iniciar o microfone. Estado:', state)
              }
            } else {
              // Outro estado - apenas logar
              console.warn('‚ö†Ô∏è Estado inesperado do reconhecimento:', state)
              isStartingRef.current = false // Liberar lock
            }
          } catch (e) {
            console.error('‚ùå Erro ao verificar estado do reconhecimento:', e)
            // Se n√£o conseguir verificar, assumir que n√£o funcionou
            setIsListening(false)
            isListeningRef.current = false
            isStartingRef.current = false // Liberar lock
            recognitionRef.current = null
            console.warn('‚ö†Ô∏è Erro ao verificar o estado do microfone')
          }
        } else {
          // Handle mudou ou j√° est√° ouvindo - liberar lock
          isStartingRef.current = false
        }
      }, 1000)

        // Armazenar timer no handle para limpar se necess√°rio
        ; (handle as any).fallbackTimer = fallbackTimer
    } catch (error: any) {
      console.error('‚ùå Erro ao iniciar escuta:', error)
      isStartingRef.current = false // Liberar lock em caso de erro

      // Se o erro for "already started", apenas logar
      if (error.message && error.message.includes('already started')) {
        console.log('‚ÑπÔ∏è Reconhecimento j√° estava iniciado, continuando...')
        setIsListening(true)
        isListeningRef.current = true
        isStartingRef.current = false // Liberar lock
        return
      }
      setIsListening(false)
      isListeningRef.current = false
      recognitionRef.current = null
      autoResumeRequestedRef.current = false
      setShouldAutoResume(false)
    }
  }, [isOpen, isProcessing, isSpeaking, sendMessage, stopListening, setShouldAutoResume])

  // REMOVIDO: N√£o desligar microfone quando a IA fala
  // O microfone deve permanecer sempre ativo para capturar a resposta do usu√°rio
  // O usu√°rio pode interromper a IA se necess√°rio

  // üé§ LIGAR MICROFONE AUTOMATICAMENTE quando a IA terminar de falar
  // CR√çTICO: O microfone DEVE ligar sempre que a IA terminar de falar
  // Este useEffect √© um BACKUP caso o evento noaImmediateListeningRequest n√£o funcione
  useEffect(() => {
    // Detectar quando a IA termina de falar (mudan√ßa de isSpeaking: true -> false)
    const wasSpeaking = wasSpeakingRef.current
    const justFinishedSpeaking = wasSpeaking && !isSpeaking && !isProcessing
    const hasActiveSimulation = hasActiveSimulationRef.current

    if (justFinishedSpeaking) {
      console.log('üîä [BACKUP] IA terminou de falar, preparando para ligar microfone automaticamente...', {
        wasSpeaking,
        isSpeaking,
        isProcessing,
        hasActiveSimulation
      })

      // Durante avalia√ß√µes, usar delay menor e ser mais agressivo no rein√≠cio
      const delay = hasActiveSimulation ? 300 : 600

      // Aguardar um pequeno delay para garantir que a fala terminou completamente
      const autoStartTimer = setTimeout(() => {
        // SIMPLIFICADO: Apenas verificar se o chat est√° aberto
        if (!isOpen || isRecordingConsultation || showPatientSelector) {
          return
        }

        // Verificar se j√° est√° realmente ouvindo
        let recognitionActuallyActive = false
        if (recognitionRef.current && recognitionRef.current.recognition) {
          try {
            const currentState = recognitionRef.current.recognition.state
            recognitionActuallyActive = currentState === 'listening' || currentState === 'starting'
            if (recognitionActuallyActive) {
              return // J√° est√° ouvindo
            }
          } catch (e) {
            // Ignorar erro
          }
        }

        // N√ÉO limpar estado - deixar que o onend cuide do rein√≠cio
        // Isso evita abortar o microfone desnecessariamente

        // Sempre tentar ligar se n√£o est√° ativo
        if (!isStartingRef.current) {
          console.log('üé§‚úÖ [BACKUP] Ligando microfone automaticamente ap√≥s IA terminar de falar')
          startListening().catch(error => {
            console.error('‚ùå [BACKUP] Erro ao ligar microfone:', error)
            // Tentar novamente ap√≥s um delay se falhar
            setTimeout(() => {
              if (!isStartingRef.current && isOpen) {
                startListening().catch(err => {
                  console.error('‚ùå [BACKUP] Erro ao tentar ligar microfone novamente:', err)
                })
              }
            }, 500)
          })
        }
      }, delay)

      return () => {
        clearTimeout(autoStartTimer)
      }
    }

    // Atualizar ref para rastrear mudan√ßas (sempre atualizar)
    // Atualizar timestamp quando a IA termina de falar
    if (wasSpeakingRef.current && !isSpeaking) {
      lastSpeechEndTimeRef.current = Date.now()
      console.log('üîá IA terminou de falar, registrando timestamp para evitar eco')
    }
    wasSpeakingRef.current = isSpeaking
  }, [isSpeaking, isProcessing, isOpen, isRecordingConsultation, showPatientSelector, isListening, startListening])

  // REMOVIDO: L√≥gica autom√°tica de rein√≠cio do microfone
  // Controle 100% manual - usu√°rio clica no bot√£o para ligar/desligar
  // Isso evita loops infinitos e problemas de rein√≠cio autom√°tico

  // REMOVIDO: L√≥gica de auto-resume

  // üîç VERIFICA√á√ÉO PERI√ìDICA DO ESTADO DO RECONHECIMENTO (DESABILITADA PARA EVITAR LOOPS)
  // Este hook foi desabilitado porque estava causando loops infinitos de iniciar/parar microfone
  // O estado do microfone √© gerenciado pelos eventos onstart/onend do SpeechRecognition API
  // useEffect(() => {
  //   if (!isListening) return
  //   // ... c√≥digo desabilitado ...
  // }, [isListening])

  // üé§ GERENCIAR MICROFONE quando o chat fechar
  useEffect(() => {
    if (!isOpen) {
      // Parar microfone quando fechar o chat (exceto durante simula√ß√µes ativas)
      const hasActiveSimulation = hasActiveSimulationRef.current
      if (hasActiveSimulation) {
        console.log('üé≠ [SIMULA√á√ÉO] Chat fechado mas simula√ß√£o ativa - mantendo microfone')
        return
      }

      if (isListening || isListeningRef.current) {
        console.log('üõë Parando microfone ao fechar chat')
        stopListening()
      }
      // Resetar flag quando o chat fecha
      hasUserEnabledMicRef.current = false
      console.log('üîÑ Flag hasUserEnabledMic resetada (chat fechado)')
    }
    // N√ÉO iniciar automaticamente ao abrir - o usu√°rio deve clicar no bot√£o
    // Isso evita solicita√ß√µes de permiss√£o n√£o solicitadas
  }, [isOpen, stopListening]) // Apenas quando isOpen muda

  // üé§ LISTENER DE EVENTO - Ligar microfone quando solicitado
  // Usando closure para acessar valores atuais sem recriar listener
  const handleImmediateListeningRef = useRef<((event: Event) => void) | null>(null)

  useEffect(() => {
    // Criar fun√ß√£o que sempre acessa os valores mais recentes
    handleImmediateListeningRef.current = (event: Event) => {
      console.log('üé§ Evento noaImmediateListeningRequest recebido')

      if (isRecordingConsultation || showPatientSelector) {
        console.log('‚ö†Ô∏è N√£o ligando microfone: gravando consulta ou mostrando seletor')
        return
      }

      const custom = event as CustomEvent<{ delay?: number }>
      const delay = custom.detail?.delay ?? 500

      const triggerListening = () => {
        // SIMPLIFICADO: Sempre tentar ligar o microfone se o chat estiver aberto
        // Removidas todas as verifica√ß√µes de bloqueio
        if (!isOpen) {
          console.log('‚ö†Ô∏è Chat n√£o est√° aberto, n√£o ligando microfone')
          return
        }

        // Verificar se j√° est√° realmente ouvindo
        let recognitionActuallyActive = false
        if (recognitionRef.current && recognitionRef.current.recognition) {
          try {
            const currentState = recognitionRef.current.recognition.state
            recognitionActuallyActive = currentState === 'listening' || currentState === 'starting'
            if (recognitionActuallyActive) {
              console.log('‚úÖ Microfone j√° est√° ativo, n√£o reiniciar')
              return
            }
          } catch (e) {
            // Ignorar erro e continuar
          }
        }

        // Limpar estado inconsistente se necess√°rio
        if (recognitionRef.current && !recognitionActuallyActive) {
          try {
            recognitionRef.current.recognition?.stop()
          } catch (e) {
            // Ignorar
          }
          recognitionRef.current = null
          isListeningRef.current = false
          setIsListening(false)
        }

        console.log('üé§‚úÖ Ligando microfone via evento noaImmediateListeningRequest')
        startListening().catch(error => {
          console.error('‚ùå Erro ao ligar microfone via evento:', error)
        })
      }

      // Limpar timeout anterior se existir
      if (immediateListenTimeoutRef.current) {
        window.clearTimeout(immediateListenTimeoutRef.current)
      }

      // Agendar ligar microfone ap√≥s delay
      immediateListenTimeoutRef.current = window.setTimeout(() => {
        triggerListening()
        immediateListenTimeoutRef.current = null
      }, delay)
    }

    const handler = (event: Event) => {
      if (handleImmediateListeningRef.current) {
        handleImmediateListeningRef.current(event)
      }
    }

    window.addEventListener('noaImmediateListeningRequest', handler)

    return () => {
      window.removeEventListener('noaImmediateListeningRequest', handler)
      if (immediateListenTimeoutRef.current) {
        window.clearTimeout(immediateListenTimeoutRef.current)
        immediateListenTimeoutRef.current = null
      }
    }
  }, [isOpen, isProcessing, isSpeaking, isListening, isRecordingConsultation, showPatientSelector, startListening])

  // REMOVIDO: Auto-iniciar microfone e detec√ß√£o de voz cont√≠nua
  // O microfone agora s√≥ funciona quando o usu√°rio clica no bot√£o manualmente

  const handleSend = useCallback(() => {
    if (!inputValue.trim()) return
    // N√ÉO parar microfone quando enviar mensagem - ele deve permanecer ligado
    sendMessage(inputValue)
    setInputValue('')
  }, [inputValue, sendMessage, isListening, stopListening])

  const handleKeyDown = useCallback((event: React.KeyboardEvent<HTMLInputElement>) => {
    if (event.key === 'Enter' && !event.shiftKey) {
      event.preventDefault()
      handleSend()
    }
  }, [handleSend])

  const toggleListening = useCallback(async () => {
    const hasActiveSimulation = hasActiveSimulationRef.current
    console.log('üé§ Bot√£o de microfone clicado. Estado atual:', {
      isListening,
      isListeningRef: isListeningRef.current,
      isProcessing,
      isSpeaking,
      hasActiveSimulation
    })

    // Se est√° processando ou gravando consulta, n√£o fazer nada
    if (isProcessing || isRecordingConsultation) {
      console.log('‚ö†Ô∏è N√£o √© poss√≠vel usar microfone: processando ou gravando consulta')
      return
    }

    if (isListening || isListeningRef.current) {
      // Durante avalia√ß√µes, n√£o permitir parar manualmente
      // N√ÉO permitir parar o microfone manualmente quando o chat est√° aberto
      // O microfone deve permanecer sempre ligado
      if (isOpen) {
        console.log('‚ö†Ô∏è [CHAT ABERTO] N√£o √© poss√≠vel parar microfone manualmente - ele deve permanecer ligado')
        return
      }
      if (hasActiveSimulation) {
        console.log('‚ö†Ô∏è [AVALIA√á√ÉO ATIVA] N√£o √© poss√≠vel parar microfone manualmente durante avalia√ß√£o')
        return
      }
      console.log('üõë Parando microfone manualmente (chat fechado)')
      setShouldAutoResume(false)
      stopListening()
    } else {
      console.log('‚ñ∂Ô∏è Iniciando microfone manualmente', hasActiveSimulation ? '[AVALIA√á√ÉO ATIVA]' : '')
      setShouldAutoResume(true)

      // Se a IA est√° falando, parar a fala primeiro
      if (isSpeaking && typeof window !== 'undefined' && 'speechSynthesis' in window) {
        console.log('üîá Parando fala da IA para iniciar microfone')
        window.speechSynthesis.cancel()
        window.dispatchEvent(new Event('noaStopSpeech'))
        // Aguardar um pouco para garantir que a fala parou
        await new Promise(resolve => setTimeout(resolve, 300))
      }

      // For√ßar parar qualquer reconhecimento anterior antes de iniciar novo
      if (recognitionRef.current) {
        try {
          recognitionRef.current.recognition?.stop()
          recognitionRef.current.stopped = true
        } catch (e) {
          console.warn('‚ö†Ô∏è Erro ao parar reconhecimento anterior:', e)
        }
        recognitionRef.current = null
      }

      // Resetar TODOS os estados que podem bloquear
      isListeningRef.current = false
      setIsListening(false)
      isStartingRef.current = false // For√ßar libera√ß√£o do lock

      // Limpar qualquer handle anterior que possa estar travado
      if (recognitionRef.current) {
        const handleToClean = recognitionRef.current as RecognitionHandle
        try {
          handleToClean.stopped = true
          if (handleToClean.recognition) {
            handleToClean.recognition.onresult = null
            handleToClean.recognition.onerror = null
            handleToClean.recognition.onend = null
            try {
              handleToClean.recognition.stop()
            } catch (e) {
              // Ignorar
            }
          }
        } catch (e) {
          console.warn('‚ö†Ô∏è Erro ao limpar handle anterior:', e)
        }
        recognitionRef.current = null
      }

      // Pequeno delay para garantir limpeza completa
      await new Promise(resolve => setTimeout(resolve, 300))

      // Iniciar microfone - SEMPRE tentar, mesmo se houver algum estado bloqueado
      try {
        await startListening(true) // For√ßar in√≠cio (a√ß√£o manual do usu√°rio)
        console.log('‚úÖ Microfone iniciado com sucesso', hasActiveSimulation ? '[AVALIA√á√ÉO ATIVA]' : '')
      } catch (error) {
        console.error('‚ùå Erro ao iniciar microfone:', error)
        // Tentar novamente ap√≥s um delay maior
        setTimeout(async () => {
          try {
            isStartingRef.current = false // Liberar lock novamente
            await startListening(true) // For√ßar in√≠cio novamente
            console.log('‚úÖ Microfone iniciado na segunda tentativa')
          } catch (retryError) {
            console.error('‚ùå Erro na segunda tentativa:', retryError)
            alert('N√£o foi poss√≠vel iniciar o microfone. Verifique as permiss√µes e tente novamente.')
          }
        }, 1000)
      }
    }
  }, [isListening, startListening, stopListening, setShouldAutoResume, isProcessing, isRecordingConsultation, isSpeaking])

  // Carregar pacientes dispon√≠veis
  const loadPatients = useCallback(async () => {
    if (!user) return

    try {
      const userType = normalizeUserType(user.type)
      if (userType !== 'profissional' && userType !== 'admin') return

      // Buscar pacientes do profissional
      // Primeiro buscar assessments, depois buscar dados dos pacientes
      const { data: assessments, error } = await supabase
        .from('clinical_assessments')
        .select('patient_id')
        .eq('doctor_id', user.id)
        .not('patient_id', 'is', null)

      if (error) {
        console.error('Erro ao carregar pacientes:', error)
        return
      }

      // Extrair IDs √∫nicos de pacientes
      const patientIds = [...new Set(assessments?.map((a: any) => a.patient_id).filter(Boolean) || [])]

      if (patientIds.length === 0) {
        setAvailablePatients([])
        return
      }

      // Buscar dados dos pacientes
      const { data: patients, error: patientsError } = await supabase
        .from('users')
        .select('id, name, email')
        .in('id', patientIds)

      if (patientsError) {
        console.error('Erro ao carregar dados dos pacientes:', patientsError)
        return
      }

      // Mapear pacientes
      setAvailablePatients(patients || [])
    } catch (error) {
      console.error('Erro ao carregar pacientes:', error)
    }
  }, [user])

  // Iniciar grava√ß√£o de consulta
  const handleStartConsultationRecording = useCallback(async () => {
    if (!user) return

    const userType = normalizeUserType(user.type)
    if (userType !== 'profissional' && userType !== 'admin') {
      sendMessage('Apenas profissionais podem gravar consultas.', { preferVoice: false })
      return
    }

    // Se n√£o houver paciente selecionado, mostrar seletor
    if (!selectedPatientId) {
      await loadPatients()
      setShowPatientSelector(true)
      sendMessage('Por favor, selecione o paciente para iniciar a grava√ß√£o da consulta.', { preferVoice: false })
      return
    }

    // N√ÉO parar escuta normal - o microfone deve permanecer ativo
    // A grava√ß√£o de consulta pode usar o mesmo microfone

    // Iniciar grava√ß√£o de consulta
    if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
      sendMessage('Reconhecimento de voz n√£o suportado neste navegador.', { preferVoice: false })
      return
    }

    const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition
    const recognition: any = new SpeechRecognition()
    recognition.lang = 'pt-BR'
    recognition.continuous = true
    recognition.interimResults = true

    const transcriptBuffer: string[] = []

    recognition.onresult = (event: any) => {
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const result = event.results[i]
        if (result.isFinal) {
          const transcript = result[0].transcript.trim()
          transcriptBuffer.push(transcript)
          setConsultationTranscript(prev => [...prev, transcript])

          // Adicionar mensagem visual no chat
          sendMessage(`[Grava√ß√£o] ${transcript}`, { preferVoice: false })
        }
      }
    }

    recognition.onerror = (event: any) => {
      console.error('Erro na grava√ß√£o:', event.error)
      if (event.error === 'no-speech') {
        // Reiniciar se n√£o houver fala
        try {
          recognition.start()
        } catch (e) {
          // Ignorar
        }
      }
    }

    recognition.onend = () => {
      if (isRecordingConsultation) {
        try {
          recognition.start()
        } catch (e) {
          // Ignorar
        }
      }
    }

    try {
      recognition.start()
      consultationRecognitionRef.current = recognition
      setIsRecordingConsultation(true)
      setConsultationStartTime(new Date())
      setConsultationTranscript([])
      sendMessage('üéôÔ∏è Grava√ß√£o de consulta iniciada. Diga "Parar grava√ß√£o" para finalizar.', { preferVoice: false })
    } catch (e) {
      console.error('Erro ao iniciar grava√ß√£o:', e)
      sendMessage('Erro ao iniciar grava√ß√£o. Tente novamente.', { preferVoice: false })
    }
  }, [user, selectedPatientId, isListening, stopListening, isRecordingConsultation, sendMessage, loadPatients])

  // Parar grava√ß√£o e salvar consulta
  const handleStopConsultationRecording = useCallback(async () => {
    if (!isRecordingConsultation || !user || !selectedPatientId) return

    setIsSavingConsultation(true)

    // Parar reconhecimento de voz
    if (consultationRecognitionRef.current) {
      try {
        consultationRecognitionRef.current.stop()
        consultationRecognitionRef.current = null
      } catch (e) {
        // Ignorar
      }
    }

    const endTime = new Date()
    const duration = consultationStartTime
      ? Math.round((endTime.getTime() - consultationStartTime.getTime()) / 1000 / 60) // minutos
      : 0

    const fullTranscript = consultationTranscript.join(' ')

    try {
      // Salvar em clinical_assessments
      const { data: assessment, error: assessmentError } = await supabase
        .from('clinical_assessments')
        .insert({
          patient_id: selectedPatientId,
          doctor_id: user.id,
          assessment_type: 'CONSULTA',
          status: 'completed',
          data: {
            transcript: fullTranscript,
            duration_minutes: duration,
            start_time: consultationStartTime?.toISOString(),
            end_time: endTime.toISOString()
          },
          clinical_report: `Consulta gravada em ${consultationStartTime?.toLocaleString('pt-BR')}\n\nTranscri√ß√£o:\n${fullTranscript}`,
          created_at: consultationStartTime?.toISOString() || new Date().toISOString(),
          updated_at: endTime.toISOString()
        })
        .select()
        .single()

      if (assessmentError) {
        throw assessmentError
      }

      // Salvar tamb√©m em clinical_reports se a tabela existir
      try {
        await supabase
          .from('clinical_reports')
          .insert({
            patient_id: selectedPatientId,
            professional_id: user.id,
            assessment_id: assessment.id,
            report_data: {
              type: 'CONSULTA',
              transcript: fullTranscript,
              duration_minutes: duration,
              date: consultationStartTime?.toISOString()
            },
            status: 'generated'
          })
      } catch (reportError) {
        // Ignorar se a tabela n√£o existir
        console.warn('Tabela clinical_reports n√£o dispon√≠vel:', reportError)
      }

      sendMessage(`‚úÖ Consulta gravada e salva com sucesso! Dura√ß√£o: ${duration} minutos.`, { preferVoice: false })

      // Resetar estados
      setIsRecordingConsultation(false)
      setConsultationTranscript([])
      setConsultationStartTime(null)
      setSelectedPatientId(null)
    } catch (error: any) {
      console.error('Erro ao salvar consulta:', error)
      sendMessage(`‚ùå Erro ao salvar consulta: ${error.message || 'Erro desconhecido'}`, { preferVoice: false })
    } finally {
      setIsSavingConsultation(false)
    }
  }, [isRecordingConsultation, user, selectedPatientId, consultationStartTime, consultationTranscript, sendMessage])

  // REMOVIDO: Detec√ß√£o de voz cont√≠nua e comando "Escute-se, N√¥a!"
  // O microfone agora s√≥ funciona quando o usu√°rio clica no bot√£o manualmente

  const handleFileUpload = useCallback((event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0]
    if (!file) return

    // Abrir modal de categoriza√ß√£o
    setUploadedFile(file)
    setShowUploadModal(true)

    // Resetar input para permitir selecionar o mesmo arquivo novamente
    if (fileInputRef.current) {
      fileInputRef.current.value = ''
    }
  }, [])

  // Processar upload com categorias selecionadas
  const processFileUpload = useCallback(async () => {
    if (!uploadedFile) {
      console.warn('‚ö†Ô∏è Nenhum arquivo selecionado para upload')
      return
    }

    console.log('üì§ Iniciando upload do arquivo:', uploadedFile.name)
    console.log('üìã Categoria:', uploadCategory)
    console.log('üéØ √Årea:', uploadArea)
    console.log('üë• Tipo de usu√°rio:', uploadUserType)

    setIsUploading(true)
    setUploadProgress(0)
    // N√ÉO fechar modal imediatamente - deixar aberto para mostrar progresso

    let progressInterval: NodeJS.Timeout | null = null

    try {
      // Adicionar mensagem inicial no chat
      sendMessage(`üì§ Enviando documento "${uploadedFile.name}" para a biblioteca e base de conhecimento...`, { preferVoice: false })

      progressInterval = setInterval(() => {
        setUploadProgress(prev => {
          if (prev >= 90) {
            if (progressInterval) clearInterval(progressInterval)
            return 90
          }
          return prev + 10
        })
      }, 200)

      const fileExt = uploadedFile.name.split('.').pop()?.toLowerCase()
      const fileName = `${Date.now()}_${uploadedFile.name.replace(/[^a-zA-Z0-9.-]/g, '_')}`
      const bucketName = 'documents'

      // Upload para Supabase Storage
      console.log('üì§ Fazendo upload para Supabase Storage...')
      const { data: uploadData, error: uploadError } = await supabase.storage
        .from(bucketName)
        .upload(fileName, uploadedFile)

      if (uploadError) {
        console.error('‚ùå Erro no upload para Storage:', uploadError)
        throw uploadError
      }

      console.log('‚úÖ Arquivo enviado para Storage com sucesso:', uploadData)

      // Criar signed URL para o arquivo
      let finalUrl = ''
      try {
        const { data: { publicUrl } } = supabase.storage
          .from('documents')
          .getPublicUrl(fileName)

        const { data: signedUrlData, error: signedError } = await supabase.storage
          .from('documents')
          .createSignedUrl(fileName, 2592000) // 30 dias

        if (!signedError && signedUrlData) {
          finalUrl = signedUrlData.signedUrl
        } else {
          finalUrl = publicUrl
        }
      } catch (urlError) {
        console.warn('‚ö†Ô∏è Erro ao criar URL:', urlError)
        const { data: { publicUrl } } = supabase.storage
          .from('documents')
          .getPublicUrl(fileName)
        finalUrl = publicUrl
      }

      // Mapear categoria para formato do banco (incluindo todas as categorias do modal)
      const categoryMap: Record<string, string> = {
        'ai-avatar': 'ai-avatar', // N√£o salva no banco, apenas atualiza avatar
        'ai-documents': 'ai-documents',
        'student': 'multimedia',
        'professional': 'protocols',
        'reports': 'reports',
        'research': 'research',
        'protocols': 'protocols',
        'cases': 'cases',
        'multimedia': 'multimedia'
      }

      const dbCategory = categoryMap[uploadCategory] || 'research'

      // üî• EXTRAIR CONTE√öDO REAL DO ARQUIVO
      let extractedContent = ''
      try {
        console.log('üìÑ Iniciando extra√ß√£o de conte√∫do do arquivo...')
        if (fileExt === 'pdf') {
          extractedContent = await extractTextFromPDF(uploadedFile)
        } else if (fileExt === 'docx' || fileExt === 'doc') {
          extractedContent = await extractTextFromDOCX(uploadedFile)
        } else if (fileExt === 'txt') {
          extractedContent = await uploadedFile.text()
        }

        if (extractedContent) {
          console.log(`‚úÖ Conte√∫do extra√≠do: ${extractedContent.length} caracteres`)
          // Limitar tamanho para evitar problemas (m√°ximo 500k caracteres)
          if (extractedContent.length > 500000) {
            extractedContent = extractedContent.substring(0, 500000) + '\n\n[... conte√∫do truncado para otimiza√ß√£o ...]'
          }
        } else {
          console.warn('‚ö†Ô∏è Nenhum conte√∫do extra√≠do do arquivo')
        }
      } catch (error) {
        console.error('‚ùå Erro ao extrair conte√∫do:', error)
        extractedContent = '' // Continuar mesmo sem conte√∫do
      }

      // Criar resumo inteligente do conte√∫do
      let summary = `Documento enviado pelo chat da IA Residente em ${new Date().toLocaleDateString('pt-BR')} - Categoria: ${uploadCategory}, √Årea: ${uploadArea}`
      if (extractedContent) {
        // Usar primeiras 300 caracteres como resumo
        const preview = extractedContent.substring(0, 300).replace(/\n+/g, ' ').trim()
        summary = `${summary}\n\nResumo do conte√∫do:\n${preview}${extractedContent.length > 300 ? '...' : ''}`
      }

      // Salvar metadata no banco COM CONTE√öDO REAL
      const documentMetadata = {
        title: uploadedFile.name,
        content: extractedContent, // üî• AGORA TEM CONTE√öDO REAL!
        file_type: fileExt || 'unknown',
        file_url: finalUrl,
        file_size: uploadedFile.size,
        author: user?.name || 'Usu√°rio',
        category: dbCategory,
        target_audience: uploadUserType.length > 0 ? uploadUserType : ['professional', 'student'],
        tags: ['upload', 'chat-upload', uploadCategory, uploadArea],
        isLinkedToAI: uploadCategory === 'ai-documents' || uploadCategory === 'research',
        aiRelevance: uploadCategory === 'ai-documents' ? 0.9 : 0.7,
        summary: summary,
        keywords: [fileExt || 'document', uploadCategory, uploadArea, ...uploadUserType]
      }

      // Verificar se o usu√°rio est√° autenticado
      const { data: { user: authUser } } = await supabase.auth.getUser()
      if (!authUser) {
        throw new Error('Usu√°rio n√£o autenticado. Por favor, fa√ßa login novamente.')
      }

      console.log('üë§ Usu√°rio autenticado para upload:', authUser.id)
      console.log('üíæ Salvando metadata do documento no banco...')
      console.log('üìÑ Metadata:', JSON.stringify(documentMetadata, null, 2))

      const { data: documentData, error: docError } = await supabase
        .from('documents')
        .insert(documentMetadata)
        .select()
        .single()

      if (docError) {
        console.error('‚ùå Erro ao salvar documento no banco:', docError)
        console.error('‚ùå Detalhes do erro:', {
          message: docError.message,
          details: docError.details,
          hint: docError.hint,
          code: docError.code
        })

        // Se for erro 403, informar sobre permiss√µes
        if (docError.code === '42501' || docError.message?.includes('permission denied') || docError.message?.includes('403')) {
          throw new Error('Erro de permiss√£o (403). As pol√≠ticas RLS da tabela documents precisam ser configuradas. Execute o script FIX_RLS_DOCUMENTS_TABLE.sql no Supabase SQL Editor.')
        }

        throw docError
      }

      console.log('‚úÖ Documento salvo no banco com sucesso:', documentData)

      // Verificar se o documento foi realmente salvo
      if (!documentData || !documentData.id) {
        throw new Error('Documento n√£o foi salvo corretamente no banco de dados')
      }

      // Vincular documento √† IA automaticamente se for categoria IA ou pesquisa
      if (documentData?.id && (uploadCategory === 'ai-documents' || uploadCategory === 'research')) {
        try {
          await KnowledgeBaseIntegration.linkDocumentToAI(documentData.id, documentMetadata.aiRelevance || 0.8)
          console.log('‚úÖ Documento vinculado √† IA:', documentData.id)
        } catch (linkError) {
          console.warn('‚ö†Ô∏è Erro ao vincular documento √† IA (n√£o cr√≠tico):', linkError)
        }
      }

      if (progressInterval) clearInterval(progressInterval)
      setUploadProgress(100)

      // Verificar se o documento foi realmente salvo antes de confirmar
      await new Promise(resolve => setTimeout(resolve, 500)) // Aguardar 500ms para garantir que o banco foi atualizado

      // Verificar se o documento aparece na busca
      const verifyDoc = await supabase
        .from('documents')
        .select('id, title, file_url, created_at')
        .eq('id', documentData.id)
        .single()

      if (verifyDoc.error) {
        console.warn('‚ö†Ô∏è Documento n√£o encontrado imediatamente ap√≥s inser√ß√£o:', verifyDoc.error)
      } else {
        console.log('‚úÖ Documento verificado ap√≥s inser√ß√£o:', verifyDoc.data)
      }

      // Disparar evento para atualizar listas de documentos em outras p√°ginas
      window.dispatchEvent(new CustomEvent('documentUploaded', {
        detail: { documentId: documentData.id, title: uploadedFile.name }
      }))

      // Mensagem de sucesso com detalhes
      const categoryNames: Record<string, string> = {
        'ai-documents': 'IA Residente',
        'protocols': 'Protocolos',
        'research': 'Pesquisa',
        'cases': 'Casos',
        'multimedia': 'Multim√≠dia'
      }

      console.log('‚úÖ Upload conclu√≠do com sucesso!')

      sendMessage(`‚úÖ Documento "${uploadedFile.name}" enviado com sucesso!\n\nüìö Categoria: ${categoryNames[uploadCategory] || uploadCategory}\nüéØ √Årea: ${uploadArea}\nüë• P√∫blico: ${uploadUserType.join(', ')}\n\nO arquivo foi adicionado √† biblioteca${uploadCategory === 'ai-documents' ? ' e est√° vinculado √† base de conhecimento da N√¥a Esperan√ßa' : ''}. Agora posso usar este documento em minhas respostas!\n\nüí° Dica: Recarregue a p√°gina da biblioteca para ver o documento na lista.`, { preferVoice: false })

      // Resetar estados primeiro
      setUploadedFile(null)
      setUploadCategory('ai-documents')
      setUploadArea('cannabis')
      setUploadUserType(['professional', 'student'])
      setIsUploading(false)
      setUploadProgress(0)

      // Resetar input de arquivo para permitir novo upload
      if (fileInputRef.current) {
        fileInputRef.current.value = ''
      }

      // Fechar modal AP√ìS resetar todos os estados (com delay para mostrar sucesso)
      setTimeout(() => {
        setShowUploadModal(false)
        console.log('‚úÖ Modal de upload fechado ap√≥s sucesso')
      }, 1000) // Aumentado para 1 segundo para dar tempo de ver a mensagem de sucesso
    } catch (error: any) {
      console.error('‚ùå Erro no upload:', error)
      if (progressInterval) clearInterval(progressInterval)
      setUploadProgress(0)

      // Adicionar mensagem de erro no chat
      sendMessage(`‚ùå Erro ao fazer upload do documento "${uploadedFile?.name}": ${error.message || 'Erro desconhecido'}. Por favor, tente novamente.`, { preferVoice: false })

      // Resetar estados e fechar modal mesmo em caso de erro
      setIsUploading(false)
      setUploadedFile(null)
      setShowUploadModal(false) // Fechar modal mesmo em caso de erro

      // Resetar input de arquivo para permitir novo upload
      if (fileInputRef.current) {
        fileInputRef.current.value = ''
      }
    }
  }, [uploadedFile, uploadCategory, uploadArea, uploadUserType, sendMessage, user])

  const handleUploadClick = useCallback(() => {
    fileInputRef.current?.click()
  }, [])

  // üî• FUN√á√ÉO PARA EXTRAIR CONTE√öDO REAL DE PDFs
  const extractTextFromPDF = useCallback(async (file: File): Promise<string> => {
    try {
      if (!file.name.toLowerCase().endsWith('.pdf')) {
        return ''
      }

      console.log('üìÑ Extraindo texto do PDF:', file.name)
      const arrayBuffer = await file.arrayBuffer()
      const pdf = await pdfjsLib.getDocument({ data: arrayBuffer }).promise

      let fullText = ''

      // Extrair texto de todas as p√°ginas
      for (let pageNum = 1; pageNum <= pdf.numPages; pageNum++) {
        const page = await pdf.getPage(pageNum)
        const textContent = await page.getTextContent()
        const pageText = textContent.items
          .map((item: any) => item.str)
          .join(' ')
          .trim()

        if (pageText) {
          fullText += `\n\n--- P√°gina ${pageNum} ---\n\n${pageText}`
        }
      }

      console.log(`‚úÖ Texto extra√≠do: ${fullText.length} caracteres de ${pdf.numPages} p√°ginas`)
      return fullText.trim()
    } catch (error) {
      console.error('‚ùå Erro ao extrair texto do PDF:', error)
      return ''
    }
  }, [])

  // üî• FUN√á√ÉO PARA EXTRAIR CONTE√öDO DE DOCX (texto simples)
  const extractTextFromDOCX = useCallback(async (file: File): Promise<string> => {
    try {
      if (!file.name.toLowerCase().endsWith('.docx') && !file.name.toLowerCase().endsWith('.doc')) {
        return ''
      }

      console.log('üìÑ Tentando extrair texto do DOCX:', file.name)
      // Para DOCX, vamos tentar ler como texto primeiro
      // Em produ√ß√£o, pode usar mammoth.js ou similar
      return new Promise((resolve) => {
        const reader = new FileReader()
        reader.onload = (e) => {
          const text = e.target?.result as string || ''
          resolve(text.substring(0, 50000)) // Limitar tamanho
        }
        reader.onerror = () => resolve('')
        reader.readAsText(file, 'utf-8')
      })
    } catch (error) {
      console.error('‚ùå Erro ao extrair texto do DOCX:', error)
      return ''
    }
  }, [])

  const positionClasses = useMemo(() => getPositionClasses(position), [position])

  return (
    <>
      {!hideButton && !isOpen && (
        <button
          onClick={() => setIsOpen(true)}
          className={clsx('fixed z-50 w-16 h-16 rounded-full shadow-xl bg-gradient-to-r from-green-500 to-emerald-600 hover:from-green-400 hover:to-emerald-500 transition-all duration-300 flex items-center justify-center text-white', positionClasses)}
          data-position={position}
        >
          <Brain className="w-8 h-8" />
        </button>
      )}

      {isOpen && (
        <div
          data-position={position}
          className={clsx(
            position === 'inline'
              ? 'relative w-full h-[100%] max-h-none flex flex-col bg-slate-900 border-none'
              : 'fixed z-[9999] bg-slate-900/95 border border-slate-700 rounded-2xl sm:rounded-3xl shadow-2xl backdrop-blur-xl flex flex-col transition-all duration-300',
            position !== 'inline' && (
              isExpanded
                ? 'left-0 sm:left-[80px] lg:left-[320px] right-0 sm:right-4 top-0 sm:top-4 bottom-0 sm:bottom-4' // Mobile: tela cheia
                : position === 'bottom-right'
                  ? 'bottom-0 sm:bottom-4 right-0 sm:right-4 w-full sm:w-[600px] h-full sm:h-[85vh] max-h-full sm:max-h-[calc(100vh-2rem)]'
                  : position === 'bottom-left'
                    ? 'bottom-0 sm:bottom-4 left-0 sm:left-4 w-full sm:w-[600px] h-full sm:h-[85vh] max-h-full sm:max-h-[calc(100vh-2rem)]'
                    : position === 'top-right'
                      ? 'top-0 sm:top-4 right-0 sm:right-4 w-full sm:w-[600px] h-full sm:h-[85vh] max-h-full sm:max-h-[calc(100vh-2rem)]'
                      : 'top-0 sm:top-4 left-0 sm:left-4 w-full sm:w-[600px] h-full sm:h-[85vh] max-h-full sm:max-h-[calc(100vh-2rem)]'
            )
          )}
          style={{
            // CR√çTICO: Em mobile, garantir que o container n√£o corte elementos
            overflow: 'hidden',
            display: 'flex',
            flexDirection: 'column',
            height: '100%',
            maxHeight: '100%'
          }}
        >
          <div className="bg-gradient-to-r from-emerald-600 via-emerald-500 to-sky-500 px-5 py-2 sm:py-3 flex items-center justify-between flex-shrink-0">
            <div className="flex items-center space-x-2 sm:space-x-3">
              <NoaAnimatedAvatar size={isExpanded ? "lg" : "sm"} isListening={isListening} isSpeaking={isSpeaking} />
              <div>
                <p className="text-xs sm:text-sm text-emerald-100">N√¥a Esperan√ßa ‚Ä¢ IA Residente</p>
                <p className="text-[10px] sm:text-xs text-emerald-50/80 truncate max-w-[150px] sm:max-w-none">{userName} ‚Ä¢ {userCode.slice(0, 8)}</p>
              </div>
            </div>
            <div className="flex items-center space-x-2">
              <button
                onClick={() => setIsExpanded(!isExpanded)}
                className="p-2 rounded-full text-white/80 hover:bg-white/10 transition"
                title={isExpanded ? "Minimizar" : "Expandir"}
              >
                {isExpanded ? <Minimize2 className="w-5 h-5" /> : <Maximize2 className="w-5 h-5" />}
              </button>
              <button
                onClick={() => {
                  setIsOpen(false)
                  setIsExpanded(false)
                  closeChat()
                  setShouldAutoResume(false)
                  stopListening()
                  window.dispatchEvent(new Event('noaChatClosed'))
                }}
                className="p-2 rounded-full text-white/80 hover:bg-white/10 transition"
              >
                <X className="w-5 h-5" />
              </button>
            </div>
          </div>

          <div className="border-b border-slate-800 bg-slate-900/80 px-3 sm:px-5 py-1 sm:py-2 flex items-center justify-between text-[10px] sm:text-xs text-slate-400 flex-shrink-0">
            <span className="flex items-center gap-1 truncate"><Activity className="w-2.5 h-2.5 sm:w-3 sm:h-3" /> <span className="hidden sm:inline">√öltimo fluxo:</span> {lastIntent ?? 'Explora√ß√£o'}</span>
            <span className="flex items-center gap-1 text-slate-400 flex-shrink-0">{messages.length} intera√ß√µes</span>
            {isRecordingConsultation && (
              <span className="flex items-center gap-1 text-red-400 animate-pulse">
                <div className="w-3 h-3 rounded-full bg-red-500" />
                Gravando consulta...
              </span>
            )}
          </div>

          {/* Seletor de Paciente */}
          {showPatientSelector && !isRecordingConsultation && (
            <div className="border-b border-slate-800 bg-slate-900/90 px-5 py-4">
              <p className="text-sm text-slate-300 mb-3">Selecione o paciente:</p>
              <div className="space-y-2 max-h-40 overflow-y-auto">
                {availablePatients.length === 0 ? (
                  <p className="text-xs text-slate-400">Nenhum paciente encontrado. Voc√™ precisa ter pelo menos uma avalia√ß√£o cl√≠nica com um paciente.</p>
                ) : (
                  availablePatients.map((patient: any) => (
                    <button
                      key={patient.id}
                      onClick={() => {
                        setSelectedPatientId(patient.id)
                        setShowPatientSelector(false)
                        handleStartConsultationRecording()
                      }}
                      className="w-full text-left px-3 py-2 rounded-lg bg-slate-800 hover:bg-slate-700 text-slate-200 text-sm flex items-center gap-2 transition"
                    >
                      <User className="w-4 h-4" />
                      <span>{patient.name || patient.email}</span>
                    </button>
                  ))
                )}
              </div>
              <button
                onClick={() => setShowPatientSelector(false)}
                className="mt-3 text-xs text-slate-400 hover:text-slate-200"
              >
                Cancelar
              </button>
            </div>
          )}

          {/* Controles de Grava√ß√£o de Consulta (apenas para profissionais) */}
          {user && (normalizeUserType(user.type) === 'profissional' || normalizeUserType(user.type) === 'admin') && !showPatientSelector && (
            <div className="border-b border-slate-800 bg-slate-900/80 px-5 py-3">
              {!isRecordingConsultation ? (
                <button
                  onClick={handleStartConsultationRecording}
                  className="w-full px-4 py-2 bg-red-600 hover:bg-red-700 text-white rounded-lg font-medium flex items-center justify-center gap-2 transition"
                >
                  <Mic className="w-4 h-4 text-white" />
                  Iniciar Grava√ß√£o de Consulta
                </button>
              ) : (
                <div className="space-y-2">
                  <div className="flex items-center justify-between text-sm text-slate-300">
                    <span>Gravando consulta...</span>
                    <span className="text-red-400 animate-pulse">
                      {consultationStartTime && Math.floor((new Date().getTime() - consultationStartTime.getTime()) / 1000)}s
                    </span>
                  </div>
                  <button
                    onClick={handleStopConsultationRecording}
                    disabled={isSavingConsultation}
                    className="w-full px-4 py-2 bg-slate-700 hover:bg-slate-600 text-white rounded-lg font-medium flex items-center justify-center gap-2 transition disabled:opacity-50 disabled:cursor-not-allowed"
                  >
                    <X className="w-4 h-4" />
                    {isSavingConsultation ? 'Salvando...' : 'Parar e Salvar Consulta'}
                  </button>
                </div>
              )}
            </div>
          )}

          <div
            ref={scrollContainerRef}
            className="flex-1 overflow-y-auto px-2 sm:px-5 py-2 sm:py-4 space-y-3 sm:space-y-4 overflow-x-hidden"
            style={{
              flex: '1 1 auto',
              overflowY: 'auto',
              minHeight: 0, // Permitir que o flex funcione corretamente
              maxHeight: '100%' // Remover limite de altura que pode estar cortando
            }}
          >
            {/* Mensagem inicial da N√¥a quando n√£o h√° hist√≥rico */}
            {messages.length === 0 && (
              <div className="flex justify-start">
                <div className="max-w-[80%] px-4 py-3 rounded-2xl text-sm shadow-sm backdrop-blur-sm border bg-slate-800/90 text-slate-100 border-slate-700">
                  <p className="whitespace-pre-wrap leading-relaxed break-words">
                    Imagine ter um consult√≥rio figital com uma IA residente dedicada a voc√™, seus colegas e seus pacientes.
                    {'\n\n'}
                    Eu sou a N√¥a Esperan√ßa, IA da plataforma MedCannLab 3.0, desenvolvida com prop√≥sito humanit√°rio,
                    treinada para respeitar sua forma de trabalhar e aprender apenas com os conceitos que voc√™ escolhe ensinar.
                    {'\n\n'}
                    Como posso te ajudar agora?
                    {'\n'}‚Ä¢ Iniciar uma avalia√ß√£o cl√≠nica IMRE triaxial{'\n'}‚Ä¢ Estudar um caso com voc√™{'\n'}‚Ä¢ Revisar relat√≥rios e prontu√°rio
                  </p>
                  <span className="block text-[10px] mt-2 text-slate-400">
                    {new Date().toLocaleTimeString('pt-BR', { hour: '2-digit', minute: '2-digit' })}
                  </span>
                </div>
              </div>
            )}

            {messages.map(message => (
              <div key={message.id} className={clsx('flex', message.role === 'user' ? 'justify-end' : 'justify-start')}>
                <div
                  className={clsx(
                    'max-w-[85%] sm:max-w-[80%] px-3 sm:px-4 py-2 sm:py-3 rounded-xl sm:rounded-2xl text-sm sm:text-base shadow-sm backdrop-blur-sm border',
                    message.role === 'user'
                      ? 'bg-emerald-600/90 text-white border-emerald-400/50'
                      : 'bg-slate-800/90 text-slate-100 border-slate-700'
                  )}
                >
                  <p className="whitespace-pre-wrap leading-relaxed break-words text-sm sm:text-base">
                    {(message.metadata as Record<string, any> | undefined)?.fullContent || message.content}
                  </p>
                  <span className="block text-[9px] sm:text-[10px] mt-1.5 sm:mt-2 text-slate-400">{message.timestamp.toLocaleTimeString('pt-BR', { hour: '2-digit', minute: '2-digit' })}</span>
                </div>
              </div>
            ))}

            {isProcessing && (
              <div className="flex justify-start">
                <div className="px-4 py-3 rounded-2xl bg-slate-800/80 text-slate-300 text-sm border border-slate-700 flex items-center gap-2">
                  <Loader2 className="w-4 h-4 animate-spin" />
                  Elaborando resposta cl√≠nica...
                </div>
              </div>
            )}
          </div>

          {/* CR√çTICO: √Årea de input SEMPRE VIS√çVEL - especialmente em mobile */}
          <div
            className="border-t border-slate-800 bg-slate-900/95 px-2 sm:px-5 py-2 sm:py-3 space-y-1 sm:space-y-2 flex-shrink-0"
            style={{
              position: 'sticky',
              bottom: 0,
              zIndex: 1000,
              minHeight: '70px',
              display: 'flex',
              flexDirection: 'column',
              backgroundColor: 'rgb(15 23 42 / 0.95)',
              backdropFilter: 'blur(8px)'
            }}
          >
            {error && (
              <div className="text-xs text-amber-400 px-1">
                {error}
              </div>
            )}

            {/* Removido: Endpoints consultados - n√£o deve aparecer para o usu√°rio */}

            {/* Container principal - SEMPRE VIS√çVEL - CR√çTICO para mobile */}
            <div
              className="flex items-center gap-1.5 sm:gap-2 w-full"
              style={{
                minHeight: '60px',
                position: 'relative',
                zIndex: 101,
                display: 'flex',
                visibility: 'visible',
                opacity: 1
              }}
            >
              <input
                ref={fileInputRef}
                type="file"
                accept=".pdf,.doc,.docx,.txt,.jpg,.jpeg,.png"
                onChange={handleFileUpload}
                className="hidden"
              />

              {/* Bot√µes de a√ß√£o - SEMPRE VIS√çVEIS - CR√çTICO para mobile */}
              <div
                className="flex items-center gap-1.5 sm:gap-2 flex-shrink-0"
                style={{ display: 'flex', visibility: 'visible', opacity: 1 }}
              >
                <button
                  onClick={handleUploadClick}
                  disabled={isUploading}
                  className={clsx('p-2.5 sm:p-3 rounded-xl sm:rounded-2xl border transition flex-shrink-0',
                    isUploading
                      ? 'bg-emerald-600 text-white border-emerald-400 opacity-50 cursor-not-allowed'
                      : 'border-slate-700 text-slate-300 hover:border-emerald-400 hover:text-emerald-200'
                  )}
                  title={isUploading ? 'Enviando documento...' : 'Enviar documento para biblioteca'}
                  style={{ display: 'block', visibility: 'visible' }}
                >
                  {isUploading ? (
                    <Loader2 className="w-4 h-4 sm:w-4 sm:h-4 animate-spin" />
                  ) : (
                    <Upload className="w-4 h-4 sm:w-4 sm:h-4" />
                  )}
                </button>

                {/* Bot√£o do microfone - implementa√ß√£o simplificada */}
                <button
                  onClick={async (e) => {
                    e.preventDefault()
                    e.stopPropagation()
                    try {
                      if (isListening) {
                        stopListening()
                      } else {
                        // Verificar permiss√µes primeiro
                        const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
                        stream.getTracks().forEach(track => track.stop()) // Parar imediatamente, s√≥ verificar permiss√£o
                        startListening()
                      }
                    } catch (error) {
                      console.error('Erro ao acessar microfone:', error)
                      alert('N√£o foi poss√≠vel acessar o microfone. Verifique as permiss√µes do navegador.')
                    }
                  }}
                  disabled={isProcessing || isRecordingConsultation}
                  className={clsx(
                    'p-2.5 sm:p-3 rounded-xl sm:rounded-2xl border transition-all duration-300 flex-shrink-0',
                    isListening
                      ? 'bg-emerald-600 text-white border-emerald-400 shadow-lg shadow-emerald-500/50 hover:bg-emerald-500 cursor-pointer animate-pulse'
                      : isSpeaking
                        ? 'bg-blue-600 text-white border-blue-400 shadow-lg shadow-blue-500/50 cursor-pointer hover:bg-blue-500'
                        : 'bg-slate-800 border-slate-700 text-slate-300 hover:bg-slate-700 hover:border-emerald-400 hover:text-emerald-200 cursor-pointer',
                    (isProcessing || isRecordingConsultation) && 'opacity-50 cursor-not-allowed'
                  )}
                  title={
                    isProcessing || isRecordingConsultation
                      ? 'Aguarde...'
                      : isListening
                        ? 'üé§ Ouvindo... Clique para parar'
                        : isSpeaking
                          ? 'IA est√° falando - Clique para ativar microfone'
                          : 'üé§ Clique para ativar reconhecimento de voz'
                  }
                  aria-label={isListening ? 'Parar microfone' : 'Ativar microfone'}
                >
                  {isListening ? (
                    <Mic className="w-4 h-4 sm:w-5 sm:h-5 text-white animate-pulse" />
                  ) : isSpeaking ? (
                    <Activity className="w-4 h-4 sm:w-5 sm:h-5 text-white animate-pulse" />
                  ) : (
                    <MicOff className="w-4 h-4 sm:w-5 sm:h-5" />
                  )}
                </button>
              </div>

              {/* Input de texto - SEMPRE VIS√çVEL - CR√çTICO para mobile */}
              <input
                type="text"
                value={inputValue}
                onChange={(event) => {
                  if (!isProcessing) {
                    setInputValue(event.target.value)
                    // Se o usu√°rio come√ßar a digitar, limpar o buffer do microfone para evitar conflitos
                    if (recognitionRef.current && event.target.value !== recognitionRef.current.buffer) {
                      recognitionRef.current.buffer = ''
                    }
                  }
                }}
                onKeyDown={handleKeyDown}
                placeholder={isListening ? "üé§ Ouvindo... (ou digite aqui)" : "Digite sua mensagem aqui..."}
                disabled={isProcessing}
                autoFocus={false}
                autoComplete="off"
                spellCheck="true"
                className="flex-1 min-w-[100px] bg-slate-800 border-2 border-slate-600 text-white text-sm sm:text-base px-4 sm:px-5 py-3 sm:py-3.5 rounded-xl sm:rounded-2xl focus:outline-none focus:border-emerald-400 focus:ring-2 focus:ring-emerald-500/40 disabled:opacity-50 disabled:cursor-not-allowed transition-all"
                style={{
                  fontSize: '16px',
                  display: 'block',
                  visibility: 'visible',
                  opacity: isProcessing ? 0.5 : 1,
                  minWidth: '120px',
                  width: '100%',
                  flex: '1 1 auto',
                  zIndex: 1000,
                  position: 'relative',
                  backgroundColor: 'rgb(30 41 59)',
                  color: 'white'
                }}
              />

              {/* Bot√£o de enviar - SEMPRE VIS√çVEL */}
              <button
                onClick={(e) => {
                  e.preventDefault()
                  e.stopPropagation()
                  if (!isProcessing && inputValue.trim()) {
                    handleSend()
                  }
                }}
                disabled={!inputValue.trim() || isProcessing}
                className="p-2.5 sm:p-3 rounded-xl sm:rounded-2xl bg-gradient-to-r from-emerald-600 to-sky-500 text-white shadow-lg hover:from-emerald-500 hover:to-sky-400 transition disabled:opacity-40 disabled:cursor-not-allowed flex-shrink-0"
                style={{ display: 'block', visibility: 'visible' }}
                title={isProcessing ? 'Processando...' : 'Enviar mensagem'}
              >
                {isProcessing ? <Loader2 className="w-4 h-4 animate-spin" /> : <Send className="w-4 h-4" />}
              </button>

              {/* Bot√£o de reset se travado (aparece imediatamente quando isProcessing est√° true) */}
              {isProcessing && (
                <button
                  onClick={(e) => {
                    e.preventDefault()
                    e.stopPropagation()
                    console.log('üîÑ Resetando estado de processamento manualmente')
                    // For√ßar reset do estado imediatamente
                    if (window.confirm('A interface est√° travada. Deseja recarregar a p√°gina?')) {
                      window.location.reload()
                    }
                  }}
                  className="p-2 rounded-lg bg-red-600 hover:bg-red-500 text-white text-xs flex-shrink-0 ml-2 animate-pulse"
                  title="Resetar se travado (clique para recarregar)"
                >
                  üîÑ Reset
                </button>
              )}
            </div>
          </div>
        </div>
      )}

      {/* Modal de Upload com Categorias */}
      {showUploadModal && (
        <div className="fixed inset-0 bg-black/60 backdrop-blur-sm flex items-center justify-center z-[60] p-4">
          <div className="bg-slate-800 rounded-xl shadow-2xl max-w-2xl w-full mx-4 max-h-[90vh] overflow-y-auto">
            {/* Modal Header */}
            <div className="p-6 border-b border-slate-700">
              <div className="flex items-center justify-between">
                <h2 className="text-2xl font-bold text-white">
                  {isUploading ? 'üì§ Enviando Documento...' : 'üìö Categorizar Documento'}
                </h2>
                <button
                  onClick={() => {
                    setShowUploadModal(false)
                    setUploadedFile(null)
                    // Resetar input de arquivo para permitir novo upload
                    if (fileInputRef.current) {
                      fileInputRef.current.value = ''
                    }
                    // Resetar estados
                    setUploadCategory('ai-documents')
                    setUploadArea('cannabis')
                    setUploadUserType(['professional', 'student'])
                  }}
                  disabled={isUploading}
                  className={clsx(
                    'text-slate-400 hover:text-white transition-colors',
                    isUploading && 'opacity-50 cursor-not-allowed'
                  )}
                >
                  <X className="w-6 h-6" />
                </button>
              </div>
            </div>

            {/* Modal Content */}
            <div className="p-6 space-y-6">
              {/* Arquivo Selecionado */}
              {uploadedFile && (
                <div className="p-4 bg-slate-700/50 rounded-lg border border-slate-600">
                  <div className="flex items-center space-x-3">
                    <Upload className="w-8 h-8 text-emerald-400" />
                    <div className="flex-1">
                      <p className="text-white font-medium">{uploadedFile.name}</p>
                      <p className="text-sm text-slate-400">
                        {(uploadedFile.size / 1024 / 1024).toFixed(2)} MB
                      </p>
                    </div>
                  </div>
                </div>
              )}

              {/* Sele√ß√£o de Categoria */}
              <div>
                <label className="block text-sm font-medium text-slate-300 mb-3">
                  üìö Categoria
                </label>
                <div className="grid grid-cols-2 gap-3">
                  {[
                    { id: 'ai-documents', name: 'üß† IA Residente', desc: 'Treinar a N√¥a Esperan√ßa' },
                    { id: 'protocols', name: 'üìñ Protocolos', desc: 'Diretrizes cl√≠nicas' },
                    { id: 'research', name: 'üî¨ Pesquisa', desc: 'Artigos cient√≠ficos' },
                    { id: 'cases', name: 'üìä Casos', desc: 'Casos cl√≠nicos' },
                    { id: 'multimedia', name: 'üé• Multim√≠dia', desc: 'V√≠deos e m√≠dia' }
                  ].map((cat) => (
                    <button
                      key={cat.id}
                      onClick={() => setUploadCategory(cat.id)}
                      className={`p-4 rounded-lg border-2 transition-all text-left ${uploadCategory === cat.id
                        ? 'border-emerald-500 bg-emerald-500/10'
                        : 'border-slate-600 hover:border-slate-500 bg-slate-700/50'
                        }`}
                    >
                      <h3 className="font-semibold text-white text-sm mb-1">{cat.name}</h3>
                      <p className="text-xs text-slate-400">{cat.desc}</p>
                    </button>
                  ))}
                </div>
              </div>

              {/* Sele√ß√£o de √Årea */}
              <div>
                <label className="block text-sm font-medium text-slate-300 mb-3">
                  üéØ √Årea
                </label>
                <div className="grid grid-cols-2 gap-3">
                  {[
                    { id: 'cannabis', name: 'üåø Cannabis' },
                    { id: 'imre', name: 'üß¨ IMRE' },
                    { id: 'clinical', name: 'üè• Cl√≠nica' },
                    { id: 'research', name: 'üìà Gest√£o' }
                  ].map((area) => (
                    <button
                      key={area.id}
                      onClick={() => setUploadArea(area.id)}
                      className={`p-3 rounded-lg border-2 transition-all ${uploadArea === area.id
                        ? 'border-emerald-500 bg-emerald-500/10'
                        : 'border-slate-600 hover:border-slate-500 bg-slate-700/50'
                        }`}
                    >
                      <span className="font-semibold text-white text-sm">{area.name}</span>
                    </button>
                  ))}
                </div>
              </div>

              {/* Sele√ß√£o de Tipo de Usu√°rio */}
              <div>
                <label className="block text-sm font-medium text-slate-300 mb-3">
                  üë• Tipo de Usu√°rio
                </label>
                <div className="grid grid-cols-2 gap-3">
                  {[
                    { id: 'all', name: 'üåê Todos os Usu√°rios' },
                    { id: 'student', name: 'üéì Alunos' },
                    { id: 'professional', name: 'üë®‚Äç‚öïÔ∏è Profissionais' },
                    { id: 'patient', name: '‚ù§Ô∏è Pacientes' }
                  ].map((type) => {
                    const isSelected = uploadUserType.includes(type.id) || (type.id === 'all' && uploadUserType.length === 3)
                    return (
                      <button
                        key={type.id}
                        onClick={() => {
                          if (type.id === 'all') {
                            setUploadUserType(['professional', 'student', 'patient'])
                          } else {
                            setUploadUserType(prev =>
                              prev.includes(type.id)
                                ? prev.filter(t => t !== type.id)
                                : [...prev, type.id]
                            )
                          }
                        }}
                        className={`p-3 rounded-lg border-2 transition-all ${isSelected
                          ? 'border-emerald-500 bg-emerald-500/10'
                          : 'border-slate-600 hover:border-slate-500 bg-slate-700/50'
                          }`}
                      >
                        <span className="font-semibold text-white text-sm">{type.name}</span>
                      </button>
                    )
                  })}
                </div>
              </div>

              {/* Upload Progress */}
              {isUploading && (
                <div>
                  <div className="flex items-center justify-between mb-2">
                    <span className="text-sm text-slate-300">Enviando...</span>
                    <span className="text-sm text-slate-300">{uploadProgress}%</span>
                  </div>
                  <div className="w-full bg-slate-700 rounded-full h-2">
                    <div
                      className="bg-gradient-to-r from-emerald-500 to-sky-500 h-2 rounded-full transition-all duration-300"
                      style={{ width: `${uploadProgress}%` }}
                    />
                  </div>
                </div>
              )}

              {/* Modal Actions */}
              <div className="flex space-x-3 pt-4 border-t border-slate-700">
                <button
                  onClick={() => {
                    setShowUploadModal(false)
                    setUploadedFile(null)
                    // Resetar input de arquivo para permitir novo upload
                    if (fileInputRef.current) {
                      fileInputRef.current.value = ''
                    }
                    // Resetar estados
                    setUploadCategory('ai-documents')
                    setUploadArea('cannabis')
                    setUploadUserType(['professional', 'student'])
                  }}
                  disabled={isUploading}
                  className={clsx(
                    'flex-1 px-4 py-3 bg-slate-700 hover:bg-slate-600 text-white rounded-lg transition-colors',
                    isUploading && 'opacity-50 cursor-not-allowed'
                  )}
                >
                  Cancelar
                </button>
                <button
                  onClick={() => {
                    console.log('üñ±Ô∏è Bot√£o "Fazer Upload" clicado')
                    console.log('üìÑ Arquivo selecionado:', uploadedFile?.name)
                    console.log('üìã Categoria selecionada:', uploadCategory)
                    console.log('üéØ √Årea selecionada:', uploadArea)
                    console.log('üë• Tipos de usu√°rio:', uploadUserType)
                    if (!uploadedFile) {
                      console.error('‚ùå Nenhum arquivo selecionado!')
                      alert('Por favor, selecione um arquivo primeiro.')
                      return
                    }
                    processFileUpload()
                  }}
                  disabled={!uploadedFile || isUploading}
                  className="flex-1 px-4 py-3 bg-gradient-to-r from-emerald-600 to-sky-500 hover:from-emerald-500 hover:to-sky-400 text-white rounded-lg transition-colors disabled:opacity-50 disabled:cursor-not-allowed flex items-center justify-center font-semibold"
                >
                  {isUploading ? (
                    <>
                      <Loader2 className="w-4 h-4 animate-spin mr-2" />
                      Enviando... {uploadProgress > 0 && `${uploadProgress}%`}
                    </>
                  ) : (
                    '‚úÖ Fazer Upload'
                  )}
                </button>
              </div>
            </div>
          </div>
        </div>
      )}
    </>
  )
}

export default NoaConversationalInterface


